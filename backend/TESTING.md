# Chain Notary Backend Testing Guide

This guide shows you how to test the Chain Notary backend using the browser and Candid interface.

## 🚀 Quick Start

### Prerequisites
- ✅ DFX installed and configured
- ✅ Local network running (`dfx start --background`)
- ✅ Project built (`dfx build backend`)
- ✅ Canister deployed (`dfx deploy backend`)

### 1. Build and Deploy

```bash
# Build the canister
dfx build backend

# Deploy to local network
dfx deploy backend

# Get the canister ID
dfx canister id backend
```

### 2. Access the Candid UI

Open your browser and navigate to:
```
http://localhost:8080/?canisterId=<CANISTER_ID>
```

Replace `<CANISTER_ID>` with your actual canister ID.

## 🧪 Testing Methods

### Method 1: Browser Candid UI (Recommended)

1. **Open the Candid UI** in your browser
2. **Test each method** using the interactive interface
3. **Copy/paste the test data** below

### Method 2: Command Line

```bash
# Test document count
dfx canister call backend get_document_count
```

## 📋 Test Scenarios

### **Scenario 1: Complete Institution Setup**
*Test the full workflow from institution creation to document upload*

#### 1.1 Create Institution
**Method:** `create_institution`
**Input:**
```json
{
  "name": "Test Financial Corp",
  "email": "test@financialcorp.com"
}
```
**Expected Output:** `{ "Ok": "INST_1234567890" }` (returns generated institution ID)

#### 1.2 Create Collection
**Method:** `create_collection`
**Input:**
```json
{
  "name": "Q1 2024 Earnings",
  "description": "First quarter earnings releases for 2024",
  "external_url": "https://example.com/earnings",
  "category": { "EarningRelease" },
  "institution_id": "INST_1234567890"
}
```
**Expected Output:** `{ "Ok": "COLL_1234567890" }` (returns generated collection ID)

**Note:** The `institution_id` must reference an existing institution, or be empty for standalone collections.

#### 1.3 Upload Document
**Method:** `upload_file_and_publish_document`
**Input:**
```json
{
  "institution_id": "INST_1234567890",
  "collection_id": "COLL_1234567890",
  "document_id": "",
  "owner": "2vxsx-fae",
  "name": "Q1 2024 Earning Release",
  "company_name": "Test Financial Corp",
  "description": "First quarter 2024 financial results",
  "document_hash": "",
  "document_data": {
    "EarningRelease": {
      "earning_release_id": "ER001",
      "quarter": 1,
      "year": 2024,
      "consolidated_income_data": {
        "gross_profit": 1000000.0,
        "operating_profit": 800000.0,
        "ebitda": 900000.0,
        "profit_before_tax": 700000.0,
        "net_profit": 500000.0
        },
      "consolidated_balance_sheet_data": {
        "total_assets": 5000000.0,
        "total_equity": 3000000.0,
        "total_liabilities": 2000000.0,
        "total_liabilities_and_equity": 5000000.0
      }
    }
  },
  "file_size": 20,
  "file_type": "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
  "file_data": [80, 75, 3, 4, 20, 0, 6, 0, 8, 0, 0, 0, 33, 0, 0, 0, 0, 0, 0, 0]
}
```

**Important Notes:**
- `document_id` and `document_hash` are automatically generated by the canister
- `institution_id` and `collection_id` must reference existing entities (or be empty)
- File validation ensures proper MIME types and size limits

**Expected Output:**
```json
{
  "success": true,
  "document_id": "generated_id_here",
  "error_message": "",
  "document_hash": "calculated_hash_here"
}
```

### **Scenario 2: Query & Search Operations**
*Test all data retrieval and search functionality*

#### 2.1 Basic Queries
- **Document Count:** `get_document_count()` → should return `1`
- **Institution Count:** `get_institution_count()` → should return `1`
- **Collection Count:** `get_collection_count()` → should return `1`

#### 2.2 Data Retrieval
- **Get Document Metadata:** `get_document_metadata("generated_id")` → document record
- **Get Document File:** `get_document_file("generated_id")` → file data
- **Get Complete Document:** `get_complete_document("generated_id")` → metadata + file
- **Get Documents by Collection:** `get_documents_by_collection("COLL001")` → document array
- **Get Documents by Quarter/Year:** `get_documents_by_quarter_year(1, 2024)` → Q1 documents

#### 2.3 Search Functions
- **Search Documents:** `search_documents_by_name("Q1 2024")` → matching documents
- **Search Collections:** `search_collections_by_name("Earnings")` → matching collections
- **Search Institutions:** `search_institutions_by_name("Financial")` → matching institutions

### **Scenario 3: Analytics & AI Features**
*Test the AI-powered document analysis capabilities*

#### 3.1 Document Analysis
**Method:** `analyze_document_data`
**Input:**
```json
{
  "document_id": "generated_document_id",
  "input_data": null,
  "analysis_focus": "financial_summary"
}
```
**Expected Output:**
```json
{
  "success": true,
  "analysis": "AI-generated financial analysis content...",
  "error_message": "",
  "analysis_type": "pdf_analysis"
}
```

#### 3.2 Input Data Analysis
**Method:** `analyze_document_data`
**Input:**
```json
{
  "document_id": null,
  "input_data": "Q1 2024 Revenue: $1M, Expenses: $500K, Net Profit: $500K",
  "analysis_focus": "risk_assessment"
}
```
**Expected Output:**
```json
{
  "success": true,
  "analysis": "AI-generated risk assessment...",
  "error_message": "",
  "analysis_type": "data_analysis"
}
```

## 🔧 Test Data Generator

### Generate Test Principal
```bash
# Generate a test principal
dfx identity get-principal
```

### Generate Test Excel Data
```javascript
// In browser console, generate a small test Excel file header
// This represents the first 20 bytes of an Excel .xlsx file (ZIP format)
const excelHeader = [80, 75, 3, 4, 20, 0, 6, 0, 8, 0, 0, 0, 33, 0, 0, 0, 0, 0, 0, 0];
console.log(excelHeader); // Copy this array for Excel file testing
```

### Generate Test Image Data
```javascript
// In browser console, generate a small test image
const canvas = document.createElement('canvas');
canvas.width = 10;
canvas.height = 10;
const ctx = canvas.getContext('2d');
ctx.fillStyle = 'red';
ctx.fillRect(0, 0, 10, 10);
const blob = await new Promise(resolve => canvas.toBlob(resolve, 'image/jpeg'));
const arrayBuffer = await blob.arrayBuffer();
const uint8Array = new Uint8Array(arrayBuffer);
console.log(Array.from(uint8Array)); // Copy this array
```

## 🐛 Common Issues & Solutions

### Issue 1: Canister Not Found
```bash
# Solution: Check if canister is deployed
dfx canister status backend
```

### Issue 2: Method Not Found
```bash
# Solution: Check candid interface
dfx canister call backend get_document_count
```

### Issue 3: Validation Errors
- **Institution ID**: Must be 3-50 characters
- **Collection ID**: Must be 1-100 characters
- **File Size**: Maximum 10MB
- **File Type**: Must be supported MIME type

## 📊 Expected Results by Scenario

### **Scenario 1: Complete Institution Setup**
*After running all three steps (institution → collection → document):*

1. **Institution Status:**
   - `get_institution_count()` → `1`
   - `get_institution_metadata("INST_1234567890")` → institution data
   - Institution's collections list contains "COLL_1234567890"

2. **Collection Status:**
   - `get_collection_count()` → `1`
   - `get_collections_by_institution("INST_1234567890")` → collection data
   - Collection's documents list contains the uploaded document ID

3. **Document Status:**
   - `get_document_count()` → `1`
   - `get_document_file(document_id)` → file data
   - `get_documents_by_owner(owner)` → document IDs
   - `get_documents_by_collection("COLL_1234567890")` → document data

### **Scenario 2: Query & Search Operations**
*All query functions should return expected data:*

1. **Count Queries:** All return `1` (after setup)
2. **Data Retrieval:** Return proper document/collection/institution data
3. **Search Functions:** Return matching results based on search terms

### **Scenario 3: Analytics & AI Features**
*AI analysis should work correctly:*

1. **Document Analysis:** Returns AI-generated analysis with proper type
2. **Input Analysis:** Returns AI-generated analysis for raw data
3. **Error Handling:** Proper error messages for invalid requests



## 🔍 Debugging Tips

### Check Canister Logs
```bash
# Check canister status and logs
dfx canister status backend
```

### Verify Candid Interface
```bash
# Check available methods
dfx canister call backend get_document_count
```

### Test Error Handling
```bash
# Try invalid inputs to test validation
dfx canister call backend create_institution '("", "Name", "email@test.com")'
```

## 🎯 Success Criteria

✅ **All methods respond without errors**
✅ **Institutions can be created and managed**
✅ **Collections can be created and managed**
✅ **Documents can be uploaded and retrieved**
✅ **Search and query functions work correctly**
✅ **Error handling works properly**
✅ **Data persistence between calls**

## 📝 Test Checklist

### **Setup & Deployment**
- [ ] Deploy canister successfully
- [ ] Access Candid UI in browser
- [ ] Verify canister is responding

### **Scenario 1: Complete Institution Setup**
- [ ] Create institution successfully
- [ ] Create collection linked to institution
- [ ] Upload document to collection
- [ ] Verify all relationships are properly established

### **Scenario 2: Query & Search Operations**
- [ ] Test all count queries
- [ ] Test data retrieval functions
- [ ] Test search functionality
- [ ] Verify data persistence between calls

### **Scenario 3: Analytics & AI Features**
- [ ] Test document analysis with valid document ID
- [ ] Test input data analysis with raw data
- [ ] Test error handling for invalid requests
- [ ] Verify AI responses are relevant and properly formatted

### **Error Handling & Validation**
- [ ] Test validation rules (file size, type, data length)
- [ ] Test relationship validation (non-existent references)
- [ ] Test ownership restrictions
- [ ] Test deletion protection rules

## 🚨 Important Notes

1. **Local Network**: Tests run on local network (`dfx start`)
2. **Principal IDs**: Use `2vxsx-fae` for anonymous calls
3. **File Size**: Keep test files under 10MB
4. **File Types**: Supports images (JPEG, PNG), documents (PDF, text), and Excel files
5. **Persistence**: Data persists between calls in local network
6. **Validation**: All inputs are validated for format and length
7. **Ownership**: Only owners can modify their institutions, collections, and documents
8. **Memory Management**: Uses stable memory with separate storage areas for optimal performance
9. **Relationship Validation**: Collections must reference existing institutions, documents must reference existing collections
10. **Analytics**: AI-powered analysis requires valid document IDs or input data 